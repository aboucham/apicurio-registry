# Title: ApiCurio Registry High Availability based on AMQ Streams and Mirror Maker 2
Environment Setup:

- Streams for Apache Kafka: 2.7.0
- Red Hat build of Apicurio Registry: 2.6.5

Prerequisites:

- Install Streams for Apache Kafka from OperatorHub
- Install Red Hat build of Apicurio Registry from OperatorHub


# I. Kafka Cluster Creation

Create the `source` namespace: `oc new-project source`

Create Kafka clusters using Kafka CR YAML configuration

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: source
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      default.replication.factor: 3
      inter.broker.protocol.version: '3.7'
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    listeners:
      - name: plain
        port: 9092
        tls: false
        type: internal
      - name: tls
        port: 9093
        tls: true
        type: internal
    replicas: 3
    storage:
      type: jbod
      volumes:
        - deleteClaim: false
          id: 0
          size: 1Gi
          type: persistent-claim
    version: 3.7.0
  zookeeper:
    replicas: 3
    storage:
      deleteClaim: false
      size: 1Gi
      type: persistent-claim
EOF
----

Create the `target` namespace: `oc new-project target`

Create Kafka clusters using Kafka CR YAML configuration

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster-tgt
  namespace: target
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      default.replication.factor: 3
      inter.broker.protocol.version: '3.7'
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    listeners:
      - name: plain
        port: 9092
        tls: false
        type: internal
      - name: tls
        port: 9093
        tls: true
        type: internal
    replicas: 3
    storage:
      type: jbod
      volumes:
        - deleteClaim: false
          id: 0
          size: 1Gi
          type: persistent-claim
    version: 3.7.0
  zookeeper:
    replicas: 3
    storage:
      deleteClaim: false
      size: 1Gi
      type: persistent-claim
EOF
----

### 2. Depploy ApiCurio Registry:

Deploy the `ApicurioRegistry CR` in the `source` namespace:

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: registry.apicur.io/v1
kind: ApicurioRegistry
metadata:
  name: apicurioregistry-kafkasql
  namespace: source
spec:
  configuration:
    kafkasql:
      bootstrapServers: 'my-cluster-kafka-bootstrap.source.svc:9092'
    persistence: kafkasql
EOF
----

        
## 3. Setup Mirror Maker 2 between Source and Target:

- Deploy `Kafka Mirror Maker 2 CR` on the `target` namespace :

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaMirrorMaker2
metadata:
  name: my-mm2
  namespace: target
spec:
  clusters:
    - alias: my-cluster
      bootstrapServers: 'my-cluster-kafka-bootstrap.source.svc:9092'
    - alias: my-cluster-tgt
      bootstrapServers: 'my-cluster-tgt-kafka-bootstrap.target.svc:9092'
      config:
        config.storage.replication.factor: -1
        offset.storage.replication.factor: -1
        ssl.cipher.suites: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
        ssl.enabled.protocols: TLSv1.2
        ssl.protocol: TLSv1.2
        status.storage.replication.factor: -1
  connectCluster: my-cluster-tgt
  jmxOptions: {}
  livenessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 60
  logging:
    loggers:
      connect.root.logger.level: INFO
      log4j.logger.org.apache.kafka.connect.runtime.WorkerSinkTask: INFO
      log4j.logger.org.apache.kafka.connect.runtime.WorkerSourceTask: INFO
    type: inline
  mirrors:
    - checkpointConnector:
        config:
          value.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          emit.checkpoints.enabled: true
          sync.group.offsets.interval.seconds: 20
          key.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          sync.group.offsets.enabled: true
          checkpoints.topic.replication.factor: -1
          emit.checkpoints.interval.seconds: 20
          refresh.groups.interval.seconds: 20
          replication.policy.class: org.apache.kafka.connect.mirror.IdentityReplicationPolicy
        tasksMax: 10
      groupsPattern: .*
      sourceCluster: my-cluster
      sourceConnector:
        config:
          offset-syncs.topic.replication.factor: -1
          value.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          offset-syncs.topic.location: target
          refresh.topics.interval.seconds: 20
          sync.topic.acls.enabled: false
          key.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          replication.factor: -1
          sync.topic.configs.enabled: true
          replication.policy.class: org.apache.kafka.connect.mirror.IdentityReplicationPolicy
        tasksMax: 10
      targetCluster: my-cluster-tgt
      topicsPattern: .*
  readinessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 60
  replicas: 1
EOF
----

Disable the `UnidirectionalTopicOperator` feature in order to observe the creation of the default topic `kafkasql-journal` on the `target` namespace.

`oc edit subscription amq-streams -n openshift-operators`

Add the following env `STRIMZI_FEATURE_GATES` with the value `-UnidirectionalTopicOperator`:

[source, yaml,indent=0]
----
spec:
  channel: stable
  installPlanApproval: Automatic
  name: amq-streams
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: amqstreams.v2.7.0-2
  config:
    env:
    - name: STRIMZI_FEATURE_GATES
      value: "-UnidirectionalTopicOperator"
----

Once the topic is created on the `target` namespace, check using `oc get kt`.

# 4. Failover Test:

Failover from `source` to `target`:

Edit the bootstrapServers in `ApicurioRegistry CR` in the `source` namespace to the following:

      bootstrapServers: 'my-cluster-kafka-bootstrap.source.svc:9092,my-cluster-tgt-kafka-bootstrap.target.svc:9092'

Let's simulate the unavailability of `my-cluster`:

[source, yaml,indent=0]
----
oc annotate Kafka my-cluster strimzi.io/pause-reconciliation="true"
oc delete sps my-cluster-kafka
----

Logs shows:

[source, yaml,indent=0]
----
apicurioregistry-kafkasql-deployment-56c68cfb75-fzcn2 registry 2024-10-18 09:42:15 INFO <_> [org.apache.kafka.clients.NetworkClient] (kafka-producer-network-thread | apicurio-registry-producer) [Producer clientId=apicurio-registry-producer] Node -1 disconnected.
apicurioregistry-kafkasql-deployment-56c68cfb75-fzcn2 registry 2024-10-18 09:42:25 INFO <> [org.apache.kafka.clients.NetworkClient] (KSQL Kafka Consumer Thread) [Consumer clientId=consumer-apicurio-registry-60fa6ebb-d902-42bc-adf8-1d4d32c066b5-1, groupId=apicurio-registry-60fa6ebb-d902-42bc-adf8-1d4d32c066b5] Node -1 disconnected.
apicurioregistry-kafkasql-deployment-56c68cfb75-fzcn2 registry 2024-10-18 09:42:25 INFO <> [org.apache.kafka.clients.NetworkClient] (KSQL Kafka Consumer Thread) [Consumer clientId=consumer-apicurio-registry-60fa6ebb-d902-42bc-adf8-1d4d32c066b5-1, groupId=apicurio-registry-60fa6ebb-d902-42bc-adf8-1d4d32c066b5] Node -1 disconnected.
----

Check that the apicurio consumer group moves to the target cluster: `my-cluster-tgt`:

[source, yaml,indent=0]
----
#!/usr/bin/env bash
STRIMZI_IMAGE="registry.redhat.io/amq7/amq-streams-kafka-32-rhel8:2.2.0"
krun() { kubectl run krun-"$(date +%s)" -it --rm --restart="Never" --image="$STRIMZI_IMAGE" -- "$@"; }
krun /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server my-cluster-tgt-kafka-bootstrap.target.svc:9092 --list
----

[source, yaml,indent=0]
----
The output should be like:
If you don't see a command prompt, try pressing enter.
apicurio-registry-b4379aa3-df78-41f5-8070-face8e4d05f1
apicurio-registry-0138eff7-5b61-45cd-a299-f31a5d839e1b
apicurio-registry-18d4b767-13a4-4d06-8f4d-83edbb4bbeb5
apicurio-registry-60fa6ebb-d902-42bc-adf8-1d4d32c066b5
apicurio-registry-c18dca3c-897f-4ed5-9ef1-e198c5a9d8fa
__strimzi-topic-operator-kstreams
pod "krun-1729245994" deleted
----

Run the webconsole and get access to the artifacts.
