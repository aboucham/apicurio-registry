# Title: ApiCurio Registry High Availability baased on AMQ Streams and Mirror Maker 2
Environment Setup:

- Streams for Apache Kafka: 2.7.0
- Red Hat build of Apicurio Registry: 2.6.5

Prerequisites:

- Install Streams for Apache Kafka from OperatorHub
- Install Red Hat build of Apicurio Registry from OperatorHub


# I. Kafka Cluster Creation

Create the `source` namespace: `oc new-project source`

Create Kafka clusters using Kafka CR YAML configuration

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: source
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      default.replication.factor: 3
      inter.broker.protocol.version: '3.7'
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    listeners:
      - name: plain
        port: 9092
        tls: false
        type: internal
      - name: tls
        port: 9093
        tls: true
        type: internal
    replicas: 3
    storage:
      type: ephemeral
    version: 3.7.0
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
EOF
----

Create the `target` namespace: `oc new-project target`

Create Kafka clusters using Kafka CR YAML configuration

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster-tgt
  namespace: target
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      default.replication.factor: 3
      inter.broker.protocol.version: '3.7'
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    listeners:
      - name: plain
        port: 9092
        tls: false
        type: internal
      - name: tls
        port: 9093
        tls: true
        type: internal
    replicas: 3
    storage:
      type: ephemeral
    version: 3.7.0
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
EOF
----

### 2. Depploy ApiCurio Registry:

Deploy the `ApicurioRegistry CR` in the `source` namespace:

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: registry.apicur.io/v1
kind: ApicurioRegistry
metadata:
  name: apicurioregistry-kafkasql
  namespace: source
spec:
  configuration:
    kafkasql:
      bootstrapServers: 'my-cluster-kafka-bootstrap.source.svc:9092'
    persistence: kafkasql
EOF
----

        
## 3. Setup Mirror Maker 2 between Source and Target:

- Deploy `Kafka Mirror Maker 2 CR` on the `target` namespace :

[source, yaml,indent=0]
----
oc create -f - <<EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaMirrorMaker2
metadata:
  name: my-mm2
  namespace: target
spec:
  clusters:
    - alias: my-cluster
      bootstrapServers: 'my-cluster-kafka-bootstrap.source.svc:9092'
    - alias: my-cluster-tgt
      bootstrapServers: 'my-cluster-tgt-kafka-bootstrap.target.svc:9092'
      config:
        config.storage.replication.factor: -1
        offset.storage.replication.factor: -1
        ssl.cipher.suites: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
        ssl.enabled.protocols: TLSv1.2
        ssl.protocol: TLSv1.2
        status.storage.replication.factor: -1
  connectCluster: my-cluster-tgt
  jmxOptions: {}
  livenessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 60
  logging:
    loggers:
      connect.root.logger.level: INFO
      log4j.logger.org.apache.kafka.connect.runtime.WorkerSinkTask: INFO
      log4j.logger.org.apache.kafka.connect.runtime.WorkerSourceTask: INFO
    type: inline
  mirrors:
    - checkpointConnector:
        config:
          value.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          emit.checkpoints.enabled: true
          sync.group.offsets.interval.seconds: 20
          key.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          sync.group.offsets.enabled: true
          checkpoints.topic.replication.factor: -1
          emit.checkpoints.interval.seconds: 20
          refresh.groups.interval.seconds: 20
          replication.policy.class: org.apache.kafka.connect.mirror.IdentityReplicationPolicy
        tasksMax: 10
      groupsPattern: .*
      sourceCluster: my-cluster
      sourceConnector:
        config:
          offset-syncs.topic.replication.factor: -1
          value.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          offset-syncs.topic.location: target
          refresh.topics.interval.seconds: 20
          sync.topic.acls.enabled: false
          key.converter: org.apache.kafka.connect.converters.ByteArrayConverter
          replication.factor: -1
          sync.topic.configs.enabled: true
          replication.policy.class: org.apache.kafka.connect.mirror.IdentityReplicationPolicy
        tasksMax: 10
      targetCluster: my-cluster-tgt
      topicsPattern: .*
  readinessProbe:
    initialDelaySeconds: 120
    timeoutSeconds: 60
  replicas: 1
EOF
----

Disable the `UnidirectionalTopicOperator` feature in order to observe the creation of the default topic `kafkasql-journal` on the `target` namespace.

`oc edit subscription amq-streams -n openshift-operators`

Add the following env `STRIMZI_FEATURE_GATES` with the value `-UnidirectionalTopicOperator`:

[source, yaml,indent=0]
----
spec:
  channel: stable
  installPlanApproval: Automatic
  name: amq-streams
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: amqstreams.v2.7.0-2
  config:
    env:
    - name: STRIMZI_FEATURE_GATES
      value: "-UnidirectionalTopicOperator"
---

Once the topic is created on the `target` namespace, check using `oc get kt`.

We can test the failover:

Failover from source to target:

      bootstrapServers: 'my-cluster-tgt-kafka-bootstrap.target.svc:9092,my-cluster-kafka-bootstrap.source.svc:9092'

